{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "FdlVnwrfJNN9",
      "metadata": {
        "id": "FdlVnwrfJNN9"
      },
      "source": [
        "# Heart Failure Prediction\n",
        "\n",
        "Trabalho final da disciplina de Engenharia de Sistemas de Software Inteligentes do curso de Engenharia de Software da Pontifícia Universidade Católica do Rio de Janeiro (PUC-Rio).\n",
        "\n",
        "## Descrição do Projeto\n",
        "\n",
        "Este projeto é modelo de Machine Learning para predição de insuficiência cardíaca. O objetivo é permitir que os usuários enviem dados clínicos e recebam de volta a predição correspondente.\n",
        "\n",
        "### Atenção\n",
        "Este projeto é apenas um modelo desenvolvido para estudos e não deve ser usado para diagnósticos médicos reais.\n",
        "Sempre consulte um profissional de saúde qualificado para questões médicas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FSI3uYAJJ61G",
      "metadata": {
        "id": "FSI3uYAJJ61G"
      },
      "source": [
        "### Etapa 1: Importação das bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1c196cee",
      "metadata": {
        "id": "1c196cee"
      },
      "outputs": [],
      "source": [
        "# configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Imports necessários\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZdbekGhUJ_-l",
      "metadata": {
        "id": "ZdbekGhUJ_-l"
      },
      "source": [
        "### Etapa 2: Carga do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "554ac347",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "554ac347",
        "outputId": "2971a6b6-9fff-4a24-aec2-51c7690bf503"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>RestingBP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FastingBS</th>\n",
              "      <th>MaxHR</th>\n",
              "      <th>ExerciseAngina</th>\n",
              "      <th>Oldpeak</th>\n",
              "      <th>HeartDisease</th>\n",
              "      <th>ChestPainType_ASY</th>\n",
              "      <th>ChestPainType_ATA</th>\n",
              "      <th>ChestPainType_NAP</th>\n",
              "      <th>ChestPainType_TA</th>\n",
              "      <th>RestingECG_LVH</th>\n",
              "      <th>RestingECG_Normal</th>\n",
              "      <th>RestingECG_ST</th>\n",
              "      <th>ST_Slope_Down</th>\n",
              "      <th>ST_Slope_Flat</th>\n",
              "      <th>ST_Slope_Up</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>283.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age  Sex  RestingBP  Cholesterol  FastingBS  MaxHR  ExerciseAngina  \\\n",
              "0  40.0  1.0      140.0        289.0        0.0  172.0             0.0   \n",
              "1  49.0  0.0      160.0        180.0        0.0  156.0             0.0   \n",
              "2  37.0  1.0      130.0        283.0        0.0   98.0             0.0   \n",
              "3  48.0  0.0      138.0        214.0        0.0  108.0             1.0   \n",
              "4  54.0  1.0      150.0        195.0        0.0  122.0             0.0   \n",
              "\n",
              "   Oldpeak  HeartDisease  ChestPainType_ASY  ChestPainType_ATA  \\\n",
              "0      0.0           0.0                0.0                1.0   \n",
              "1      1.0           1.0                0.0                0.0   \n",
              "2      0.0           0.0                0.0                1.0   \n",
              "3      1.5           1.0                1.0                0.0   \n",
              "4      0.0           0.0                0.0                0.0   \n",
              "\n",
              "   ChestPainType_NAP  ChestPainType_TA  RestingECG_LVH  RestingECG_Normal  \\\n",
              "0                0.0               0.0             0.0                1.0   \n",
              "1                1.0               0.0             0.0                1.0   \n",
              "2                0.0               0.0             0.0                0.0   \n",
              "3                0.0               0.0             0.0                1.0   \n",
              "4                1.0               0.0             0.0                1.0   \n",
              "\n",
              "   RestingECG_ST  ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  \n",
              "0            0.0            0.0            0.0          1.0  \n",
              "1            0.0            0.0            1.0          0.0  \n",
              "2            1.0            0.0            0.0          1.0  \n",
              "3            0.0            0.0            1.0          0.0  \n",
              "4            0.0            0.0            0.0          1.0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"https://raw.githubusercontent.com/robertheory/heart-failure-prediction/refs/heads/master/ml/heart.csv\"\n",
        "\n",
        "dataset = pd.read_csv(url)\n",
        "\n",
        "# Codifica variáveis categóricas\n",
        "dataset['Sex'] = dataset['Sex'].map({'M': 1, 'F': 0})\n",
        "dataset['ExerciseAngina'] = dataset['ExerciseAngina'].map({'Y': 1, 'N': 0})\n",
        "\n",
        "# One-hot encoding para as demais\n",
        "dataset = pd.get_dummies(dataset, columns=['ChestPainType', 'RestingECG', 'ST_Slope'])\n",
        "\n",
        "# Passa os dados para o formato float\n",
        "dataset = dataset.astype(float)\n",
        "\n",
        "# Exibe as primeiras linhas do dataset\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lme_dcZyKG_P",
      "metadata": {
        "id": "lme_dcZyKG_P"
      },
      "source": [
        "### Etapa 3: Separação em Conjuntos (Holdout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ed0294",
      "metadata": {
        "id": "a2ed0294"
      },
      "outputs": [],
      "source": [
        "test_size = 0.20 # tamanho do conjunto de teste\n",
        "seed = 7 # semente aleatória\n",
        "\n",
        "# Separação dos dados em treino e teste\n",
        "X = dataset.drop('HeartDisease', axis=1)  # Features\n",
        "y = dataset['HeartDisease']  # Target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "  test_size=test_size, random_state=seed, stratify=y)  # estratificação para manter a proporção das classes\n",
        "\n",
        "# Parâmetros e partições da validação cruzada\n",
        "scoring = 'accuracy'\n",
        "num_particoes = 10  # número de partições para validação cruzada\n",
        "\n",
        "# Ajusta o número de partições para não exceder o número mínimo de amostras por classe\n",
        "min_samples_per_class = np.min(np.bincount(y_train))\n",
        "num_particoes = min(num_particoes, min_samples_per_class)\n",
        "kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed) # validação cruzada com estratificação"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iSOvK1-rKasF",
      "metadata": {
        "id": "iSOvK1-rKasF"
      },
      "source": [
        "### Etapa 4: Criação e avaliação de modelos: linha base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7ad2ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "0d7ad2ac",
        "outputId": "bbcd8ceb-3726-486f-fcdb-28f4b25d88cc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(7) # definindo uma semente global\n",
        "\n",
        "# Lista que armazenará os modelos\n",
        "models = []\n",
        "\n",
        "# Criando os modelos e adicionando-os na lista de modelos\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Listas para armazenar os resultados\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Avaliação dos modelos\n",
        "for name, model in models:\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "fig.suptitle('Comparação dos Modelos')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fESgfggDKgGR",
      "metadata": {
        "id": "fESgfggDKgGR"
      },
      "source": [
        "### Etapa 5: Criação e avaliação de modelos: dados padronizados e normalizados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5323f615",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "5323f615",
        "outputId": "07aff17b-7d61-4e71-f00e-a882799a9b2d"
      },
      "outputs": [],
      "source": [
        "np.random.seed(7) # definindo uma semente global para este bloco\n",
        "\n",
        "# Listas para armazenar os armazenar os pipelines e os resultados para todas as visões do dataset\n",
        "pipelines = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Criando os elementos do pipeline\n",
        "\n",
        "# Algoritmos que serão utilizados\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "cart = ('CART', DecisionTreeClassifier())\n",
        "naive_bayes = ('NB', GaussianNB())\n",
        "svm = ('SVM', SVC())\n",
        "\n",
        "# Transformações que serão utilizadas\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "# Montando os pipelines\n",
        "\n",
        "# Dataset original\n",
        "pipelines.append(('KNN-orig', Pipeline([knn])))\n",
        "pipelines.append(('CART-orig', Pipeline([cart])))\n",
        "pipelines.append(('NB-orig', Pipeline([naive_bayes])))\n",
        "pipelines.append(('SVM-orig', Pipeline([svm])))\n",
        "\n",
        "# Dataset Padronizado\n",
        "pipelines.append(('KNN-padr', Pipeline([standard_scaler, knn])))\n",
        "pipelines.append(('CART-padr', Pipeline([standard_scaler, cart])))\n",
        "pipelines.append(('NB-padr', Pipeline([standard_scaler, naive_bayes])))\n",
        "pipelines.append(('SVM-padr', Pipeline([standard_scaler, svm])))\n",
        "\n",
        "# Dataset Normalizado\n",
        "pipelines.append(('KNN-norm', Pipeline([min_max_scaler, knn])))\n",
        "pipelines.append(('CART-norm', Pipeline([min_max_scaler, cart])))\n",
        "pipelines.append(('NB-norm', Pipeline([min_max_scaler, naive_bayes])))\n",
        "pipelines.append(('SVM-norm', Pipeline([min_max_scaler, svm])))\n",
        "\n",
        "# Executando os pipelines\n",
        "for name, model in pipelines:\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %.3f (%.3f)\" % (name, cv_results.mean(), cv_results.std()) # formatando para 3 casas decimais\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(25,6))\n",
        "fig.suptitle('Comparação dos Modelos - Dataset orginal, padronizado e normalizado')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names, rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b76c68",
      "metadata": {},
      "source": [
        "### Etapa 6: Otimização dos hiperparâmetros para Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "701c5210",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(7) # definindo uma semente global para este bloco\n",
        "\n",
        "param_grid = {\n",
        "    'var_smoothing': np.logspace(0, -9, num=100)\n",
        "}\n",
        "\n",
        "naive_bayes = GaussianNB()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=naive_bayes, param_grid=param_grid, scoring=scoring, cv=kfold, n_jobs=-1)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Exibindo os melhores parâmetros e o melhor resultado\n",
        "print(\"Melhores parâmetros: \", grid_result.best_params_)\n",
        "print(\"Melhor resultado: %.3f (%.3f)\" % (grid_result.best_score_, grid_result.cv_results_['std_test_score'][grid_result.best_index_]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3b2e7ea",
      "metadata": {},
      "source": [
        "### Etapa 7: Finalização do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "785a51c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Avaliação do modelo com o conjunto de testes\n",
        "\n",
        "# Preparação do modelo\n",
        "scaler = StandardScaler().fit(X_train) # ajuste do scaler com o conjunto de treino\n",
        "rescaledX = scaler.transform(X_train) # aplicação da padronização no conjunto de treino\n",
        "model = GaussianNB(var_smoothing=grid_result.best_params_['var_smoothing']) # criação do modelo com os melhores parâmetros\n",
        "model.fit(rescaledX, y_train) # treinamento do modelo\n",
        "\n",
        "# Avaliação do modelo com o conjunto de testes\n",
        "test_rescaledX = scaler.transform(X_test) # aplicação da padronização no conjunto de teste\n",
        "predictions = model.predict(test_rescaledX) # previsões com o modelo treinado\n",
        "print(accuracy_score(y_test, predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07c14b2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparação do modelo com TODO o dataset\n",
        "scaler = StandardScaler().fit(X) # ajuste do scaler com TODO o dataset\n",
        "rescaledX = scaler.transform(X) # aplicação da padronização com TODO o dataset\n",
        "model.fit(rescaledX, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0585uH_ALISu",
      "metadata": {
        "id": "0585uH_ALISu"
      },
      "source": [
        "### Etapa 8: Simulando a aplicação do modelo em dados não vistos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0734269b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0734269b",
        "outputId": "a466eef5-2628-4f7f-9e04-a1df318735a6"
      },
      "outputs": [],
      "source": [
        "# Novos dados - não sabemos a classe!\n",
        "\n",
        "# 2 entradas de teste: 1 positivas (Com Doença Cardíaca), 1 negativas (Sem Doença Cardíaca)\n",
        "# 1 - Negativa (Sem Doença Cardíaca)\n",
        "# 2 - Positiva (Com Doença Cardíaca)\n",
        "data = {\n",
        "    'Age': [45, 60],\n",
        "    'Sex': [1, 0],\n",
        "    'RestingBP': [80, 85],\n",
        "    'Cholesterol': [1, 1],\n",
        "    'FastingBS': [0, 0],\n",
        "    'MaxHR': [100, 110],\n",
        "    'ExerciseAngina': [0, 1],\n",
        "    'Oldpeak': [1.5, 2.0],\n",
        "    'ChestPainType_ASY': [0, 1],\n",
        "    'ChestPainType_ATA': [1, 0],\n",
        "    'ChestPainType_NAP': [0, 0],\n",
        "    'ChestPainType_TA': [0, 0],\n",
        "    'RestingECG_LVH': [0, 1],\n",
        "    'RestingECG_Normal': [1, 0],\n",
        "    'RestingECG_ST': [0, 0],\n",
        "    'ST_Slope_Down': [0, 1],\n",
        "    'ST_Slope_Flat': [1, 0],\n",
        "    'ST_Slope_Up': [0, 0]\n",
        "}\n",
        "\n",
        "atributos = ['Age', 'Sex', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'ChestPainType_ASY', 'ChestPainType_ATA', 'ChestPainType_NAP', 'ChestPainType_TA', 'RestingECG_LVH', 'RestingECG_Normal', 'RestingECG_ST', 'ST_Slope_Down', 'ST_Slope_Flat', 'ST_Slope_Up']\n",
        "entrada = pd.DataFrame(data, columns=atributos)\n",
        "\n",
        "array_entrada = entrada.values.astype(np.float64)  # Convertendo o DataFrame para um array NumPy de tipo float64\n",
        "# Padronização nos dados de entrada usando o scaler utilizado em X\n",
        "rescaledEntradaX = scaler.transform(array_entrada)\n",
        "print(rescaledEntradaX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d217972c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predição de classes dos dados de entrada\n",
        "description = {\n",
        "  0: \"Negativo\",\n",
        "  1: \"Positivo\"\n",
        "}\n",
        "\n",
        "saidas = model.predict(rescaledEntradaX)\n",
        "\n",
        "print('Doença Cardíaca: ')\n",
        "print([description[s] for s in saidas])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "czMttCOULjXH",
      "metadata": {
        "id": "czMttCOULjXH"
      },
      "source": [
        "### Etapa 9: Exportando o modelo para o formato PKL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pSTHoNEgLn1G",
      "metadata": {
        "id": "pSTHoNEgLn1G"
      },
      "outputs": [],
      "source": [
        "# Salvar o modelo no arquivo\n",
        "filename = 'heart_disease_model.pkl'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "# Sakvar o scaler no arquivo\n",
        "scaler_filename = 'heart_disease_scaler.pkl'\n",
        "pickle.dump(scaler, open(scaler_filename, 'wb'))\n",
        "\n",
        "print(f\"Modelo exportado para '{filename}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd00efbd",
      "metadata": {},
      "source": [
        "### Análise dos Resultados\n",
        "\n",
        "Inicialmente, foi realizada um teste com 4 algoritmos: \n",
        "\n",
        "- KNN: K-Nearest Neighbors (K Vizinhos Mais Próximos)\n",
        "- Decision Tree: Árvore de Decisão\n",
        "- Naive Bayes: Classificador Naive Bayes\n",
        "- SVM: Máquinas de Vetores de Suporte\n",
        "\n",
        "Os resultados mostraram que o modelo Naive Bayes teve o melhor desempenho, com uma acurácia de 0.85, sendo assim escolhido como modelo base.\n",
        "\n",
        "Durante a etapa de padronização e normalização dos dados, tivemos poucas diferenças significativas nas métricas de desempenho entre os modelos, mas o Naive Bayes continuou a se destacar.\n",
        "\n",
        "Foi na etapa de otimização dos hiper parâmetros que conseguimos melhorar um pouco mais o desempenho do modelo Naive Bayes, ajustando o parâmetro `var_smoothing`, o que resultou em uma leve melhoria na acurácia, agora alcançando 0.86.\n",
        "\n",
        "O modelo final, treinado com todo o conjunto de dados e utilizando os melhores hiperparâmetros encontrados, foi capaz de generalizar bem para novos exemplos, conforme demonstrado na etapa de simulação com dados não vistos. A exportação do modelo e do scaler garante a reprodutibilidade e a possibilidade de uso em aplicações futuras.\n",
        "\n",
        "**Pontos de atenção:**\n",
        "- O dataset utilizado é relativamente pequeno e pode não representar toda a diversidade de casos reais.\n",
        "- O modelo não deve ser utilizado para diagnósticos médicos reais, servindo apenas como ferramenta de estudo.\n",
        "- Novos testes com outros algoritmos podem ser explorados para aprimorar ainda mais os resultados.\n",
        "\n",
        "### Conclusão\n",
        "\n",
        "O trabalho demonstrou, de forma prática, o processo completo de desenvolvimento de um modelo de machine learning para predição de insuficiência cardíaca: desde a avaliação de diferentes algoritmos, otimização de hiperparâmetros, até a validação e exportação do modelo final. Os resultados obtidos reforçam a importância do pré-processamento e da escolha adequada dos algoritmos para problemas de classificação em saúde.\n",
        "\n",
        "Destaca-se que, apesar dos bons resultados, o uso de modelos preditivos em saúde deve ser sempre acompanhado de validação clínica e supervisão de profissionais qualificados."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZdbekGhUJ_-l",
        "lme_dcZyKG_P",
        "iSOvK1-rKasF",
        "fESgfggDKgGR",
        "FCU4TM8OK0L_"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
